{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2t1qwGqxR1sQbI77209lX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhoenixAlpha23/Pytesseract-Streamlit-App/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Google's Tesseract engine"
      ],
      "metadata": {
        "id": "DHNJ4omuq9kW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install tesseract-ocr"
      ],
      "metadata": {
        "id": "AVk4hj-fplU6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "install the python wrapper Pytesseract for this project.\n",
        "*  Numpy- array operations\n",
        "*  Pdf2image to handle PDF as input.\n",
        "* Streamlit library- to create a temporary website to use this project.\n",
        "*  pyMuPDF->fitz for image processing"
      ],
      "metadata": {
        "id": "kpvA4YXvrDko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#install necessary packages , opencv- image preprocessing, pytesseract pillow- OCR components,streamlit for demonstration purposes,\n",
        "!pip install streamlit opencv-python-headless pytesseract Pillow numpy pdf2image pyMuPDF fitz"
      ],
      "metadata": {
        "id": "gRQnwsS_pVVy",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the Streamlit App"
      ],
      "metadata": {
        "id": "gFENjrVvrsaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import io\n",
        "import fitz\n",
        "from pdf2image import convert_from_bytes\n",
        "import zipfile\n",
        "\n",
        "def ensure_gray(image):\n",
        "    \"\"\"\n",
        "    Ensures the input image is in grayscale format.\n",
        "    If the image is already grayscale, it's returned as-is.\n",
        "    If it's in color, it's converted to grayscale.\n",
        "    \"\"\"\n",
        "    if len(image.shape) == 2:\n",
        "        return image\n",
        "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "def deskew_hough(image):\n",
        "    \"\"\"\n",
        "    Applies Hough Line Transform to detect and correct skew in the image.\n",
        "    \"\"\"\n",
        "    gray = ensure_gray(image)\n",
        "    edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
        "    lines = cv2.HoughLines(edges, 1, np.pi/180, 100)\n",
        "\n",
        "    if lines is not None:\n",
        "        angle = 0\n",
        "        for rho, theta in lines[0]:\n",
        "            if theta < np.pi/4 or theta > 3*np.pi/4:\n",
        "                angle = theta\n",
        "                break\n",
        "\n",
        "        if angle != 0:\n",
        "            (h, w) = image.shape[:2]\n",
        "            center = (w // 2, h // 2)\n",
        "            M = cv2.getRotationMatrix2D(center, angle * 180 / np.pi - 90, 1.0)\n",
        "            rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
        "            return rotated\n",
        "\n",
        "    return image\n",
        "\n",
        "def preprocess_image(image, options):\n",
        "    \"\"\"\n",
        "    Applies various preprocessing techniques to improve OCR accuracy:\n",
        "    1. Converts to grayscale\n",
        "    2. Applies thresholding\n",
        "    3. Deskews the image\n",
        "    4. Inverts colors\n",
        "    5. Resizes\n",
        "    6. Applies denoising\n",
        "    \"\"\"\n",
        "    gray = ensure_gray(image)\n",
        "\n",
        "    if options['apply_threshold']:\n",
        "        _, gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    if options['apply_deskew']:\n",
        "        gray = deskew_hough(gray)\n",
        "\n",
        "    if options['apply_denoise']:\n",
        "        gray = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)\n",
        "\n",
        "    if options['apply_contrast']:\n",
        "        gray = cv2.equalizeHist(gray)\n",
        "\n",
        "    return gray\n",
        "\n",
        "def extract_text(image, options):\n",
        "    \"\"\"\n",
        "    Extracts text from the preprocessed image using pytesseract OCR.\n",
        "    \"\"\"\n",
        "    config = f\"--oem 3 --psm {options['psm']} preserve_interword_spaces=1\"\n",
        "    return pytesseract.image_to_string(image, config=config, lang=\"eng\")\n",
        "\n",
        "def process_image(uploaded_file, options):\n",
        "    \"\"\"\n",
        "    Processes an uploaded image file:\n",
        "    1. Opens the image\n",
        "    2. Converts it to a numpy array\n",
        "    3. Applies preprocessing\n",
        "    4. Extracts text using OCR\n",
        "    \"\"\"\n",
        "    image = Image.open(uploaded_file)\n",
        "    image_np = np.array(image)\n",
        "    processed_image = preprocess_image(image_np, options)\n",
        "    return extract_text(processed_image, options)\n",
        "\n",
        "def process_pdf(uploaded_file, options):\n",
        "    \"\"\"\n",
        "    Processes an uploaded PDF file:\n",
        "    1. Reads the PDF\n",
        "    2. Converts each page to an image\n",
        "    3. Preprocesses each image\n",
        "    4. Extracts text from each preprocessed image\n",
        "    5. Combines text from all pages\n",
        "    \"\"\"\n",
        "    pdf_bytes = uploaded_file.read()\n",
        "    doc = fitz.open(stream=pdf_bytes, filetype=\"pdf\")\n",
        "    texts = []\n",
        "    for page in doc:\n",
        "        pix = page.get_pixmap()\n",
        "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
        "        img_np = np.array(img)\n",
        "        processed_image = preprocess_image(img_np, options)\n",
        "        texts.append(extract_text(processed_image, options))\n",
        "    return \"\\n\\n\".join(texts)\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the Streamlit app:\n",
        "    1. Sets up the user interface\n",
        "    2. Handles file uploads\n",
        "    3. Processes uploaded files (images or PDFs)\n",
        "    4. Displays extracted text\n",
        "    5. Provides a download option for the extracted text\n",
        "    \"\"\"\n",
        "    st.title(\"Enhanced OCR Text Extraction from Images and PDFs\")\n",
        "    st.write(\"Upload multiple images or a PDF file to extract text.\")\n",
        "\n",
        "    uploaded_files = st.file_uploader(\"Choose files\", accept_multiple_files=True, type=[\"png\", \"jpg\", \"jpeg\", \"pdf\"])\n",
        "\n",
        "    st.sidebar.header(\"OCR Options\")\n",
        "    options = {\n",
        "        'apply_threshold': st.sidebar.checkbox(\"Apply Thresholding\", value=True),\n",
        "        'apply_deskew': st.sidebar.checkbox(\"Apply Deskewing\", value=True),\n",
        "        'apply_denoise': st.sidebar.checkbox(\"Apply Denoising\", value=True),\n",
        "        'apply_contrast': st.sidebar.checkbox(\"Apply Contrast Enhancement\", value=False),\n",
        "        'psm': st.sidebar.selectbox(\"Page Segmentation Mode\",\n",
        "                                    options=[3, 4, 6, 11, 12],\n",
        "                                    format_func=lambda x: f\"PSM {x}\",\n",
        "                                    help=\"3: Full auto, 4: Single column, 6: Single block of text, 11: Single text line, 12: Single word\")\n",
        "    }\n",
        "\n",
        "    if uploaded_files:\n",
        "        all_text = []\n",
        "        individual_texts = {}\n",
        "        for uploaded_file in uploaded_files:\n",
        "            try:\n",
        "                if uploaded_file.type == \"application/pdf\":\n",
        "                    text = process_pdf(uploaded_file, options)\n",
        "                else:\n",
        "                    text = process_image(uploaded_file, options)\n",
        "                all_text.append(f\"File: {uploaded_file.name}\\n\\n{text}\\n\\n{'='*50}\\n\")\n",
        "                individual_texts[uploaded_file.name] = text\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error processing {uploaded_file.name}: {str(e)}\")\n",
        "\n",
        "        combined_text = \"\\n\".join(all_text)\n",
        "        st.text_area(\"Extracted Text\", value=combined_text, height=300)\n",
        "\n",
        "        # Create a download button for the combined extracted text\n",
        "        combined_text_io = io.BytesIO(combined_text.encode('utf-8'))\n",
        "        st.download_button(\n",
        "            label=\"Download Combined Extracted Text\",\n",
        "            data=combined_text_io,\n",
        "            file_name=\"combined_extracted_text.txt\",\n",
        "            mime=\"text/plain\"\n",
        "        )\n",
        "\n",
        "        # Create a download button for individual text files\n",
        "        if len(individual_texts) > 0:\n",
        "            zip_buffer = io.BytesIO()\n",
        "            with zipfile.ZipFile(zip_buffer, \"a\", zipfile.ZIP_DEFLATED, False) as zip_file:\n",
        "                for file_name, text in individual_texts.items():\n",
        "                    zip_file.writestr(f\"{file_name}_extracted.txt\", text)\n",
        "\n",
        "            st.download_button(\n",
        "                label=\"Download Individual Extracted Texts\",\n",
        "                data=zip_buffer.getvalue(),\n",
        "                file_name=\"individual_extracted_texts.zip\",\n",
        "                mime=\"application/zip\"\n",
        "            )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aNbViHBpV0i",
        "outputId": "fe8edb63-7592-4618-a2b6-15c76ee88b19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To get the password to\n",
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwWK5YRBM6DX",
        "outputId": "d8c1433a-53c4-4bcc-9d21-642dcddabb4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Enpoint IP for localtunnel is: 34.125.254.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt &\n",
        "!npx localtunnel --port 8501 &\n",
        "\n",
        "import time\n",
        "from google.colab import files\n",
        "import IPython\n",
        "\n",
        "# Wait for Streamlit and localtunnel to start\n",
        "time.sleep(10)\n",
        "\n",
        "# Get the localtunnel URL\n",
        "localtunnel_url = !curl -s http://localhost:4040/api/tunnels | python -c \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "\n",
        "print(f\"Your Streamlit app is running at: {localtunnel_url[0]}\")\n",
        "IPython.display.HTML(f'<a href=\"{localtunnel_url[0]}\" target=\"_blank\">Click here to open the Streamlit app</a>')"
      ],
      "metadata": {
        "id": "9rbngyeqqdvf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}